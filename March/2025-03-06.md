## ğŸ“… ë‚ ì§œ: 2025-03-06

### ğŸ’¬ ìŠ¤í¬ëŸ¼
- í•™ìŠµ ëª©í‘œ 1 : Zero-Shot Learning
- í•™ìŠµ ëª©í‘œ 2 : TensorBoard, ì •ê·œí™” ê¸°ë²•
  
### ğŸ“’ ê³µë¶€í•œ ë‚´ìš©
---

ë”¥ëŸ¬ë‹ êµ¬ì¡° ì „ë°˜ì  ì´ë¯¸ì§€ <br><br>

ìµœì†Œ, ìµœëŒ€ê°’ì„ ì°¾ëŠ” ê²Œ ì•„ë‹Œ, ê·¸ ê°’ì´ ë˜ë„ë¡ í•˜ëŠ” argument(ì¸ìˆ˜)ë¥¼ ì°¾ëŠ” ê²ƒì´ ëª©í‘œ

---

Zero-Shot Learning - í•™ìŠµí•œ ì ì´ ì—†ì–´ë„ ìƒˆë¡œìš´ ê°œë… ìƒì„± ê°€ëŠ¥

Few-Shot Learning - ì ì€ ì–‘ì˜ í•™ìŠµ ë°ì´í„°ë¡œë„ ì¼ë°˜í™” ëŠ¥ë ¥ì„ ê°–ë„ë¡ í•˜ëŠ” ê¸°ìˆ 

---

TensorBoard : í•™ìŠµ ê³¼ì •ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ì‹œê°í™”<br><br>

- ì‚¬ìš© ë°©ë²• (PyTorch)
    1. **í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ë° ì„¤ì •**
        
        PyTorch, TensorBoard ë“±ì„ ì„í¬íŠ¸í•˜ê³  ë¡œê·¸ë¥¼ ì €ì¥í•  ë””ë ‰í† ë¦¬ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.
        
        ```python
        import torch
        import torch.nn as nn
        import torch.optim as optim
        from torch.utils.tensorboard import SummaryWriter
        import torchvision
        import torchvision.transforms as transforms
        import datetime
        
        # í˜„ì¬ ì‹œê°„ì„ ê¸°ë°˜ìœ¼ë¡œ ë¡œê·¸ ë””ë ‰í† ë¦¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        log_dir = "logs/" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
        
        # SummaryWriterë¥¼ ì‚¬ìš©í•´ TensorBoardì— ê¸°ë¡í•  ê°ì²´ë¥¼ ë§Œë“­ë‹ˆë‹¤.
        writer = SummaryWriter(log_dir=log_dir)
        ```
        
    2. **ëª¨ë¸ í•™ìŠµ ê³¼ì •ì—ì„œ TensorBoardì— ê¸°ë¡í•˜ê¸°**
        
        í•™ìŠµ ë£¨í”„ ë‚´ë¶€ì—ì„œ ì†ì‹¤(loss), ì •í™•ë„(accuracy) ë“± ì§€í‘œë¥¼ ê³„ì‚°í•œ ë’¤ `add_scalar()` ë©”ì„œë“œë¥¼ í†µí•´ ë¡œê·¸ë¡œ ê¸°ë¡í•©ë‹ˆë‹¤.
        
        ```python
        for epoch in range(num_epochs):
            running_loss = 0.0
            correct, total = 0, 0
        
            # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ì„œ ëª¨ë¸ì— ì…ë ¥í•©ë‹ˆë‹¤.
            for i, (inputs, labels) in enumerate(trainloader):
                # ì˜µí‹°ë§ˆì´ì €ì˜ ê¸°ìš¸ê¸°(gradient)ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
                optimizer.zero_grad()
                
                # ëª¨ë¸ì— ì…ë ¥ì„ ì „ë‹¬í•˜ì—¬ ìˆœì „íŒŒ(forward)ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
                outputs = model(inputs)
                
                # ì˜ˆì¸¡ê°’(outputs)ê³¼ ì‹¤ì œê°’(labels)ì„ ë¹„êµí•´ ì†ì‹¤(loss)ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
                loss = criterion(outputs, labels)
                
                # ì—­ì „íŒŒ(backward)ë¥¼ í†µí•´ ê°€ì¤‘ì¹˜ì— ëŒ€í•œ ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
                loss.backward()
                
                # ì˜µí‹°ë§ˆì´ì €ë¡œ ê°€ì¤‘ì¹˜ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
                optimizer.step()
        
                # ë°°ì¹˜ë³„ ì†ì‹¤ê°’ì„ running_lossì— ê³„ì† ë”í•´ì¤ë‹ˆë‹¤.
                running_loss += loss.item()
                
                # ë°°ì¹˜ ë‹¨ìœ„ì˜ ì˜ˆì¸¡ê°’ì„ ë„ì¶œí•˜ê³ , ì •í™•ë„ë¥¼ ê³„ì‚°í•˜ê¸° ìœ„í•œ ì§€í‘œë¥¼ ëˆ„ì í•©ë‹ˆë‹¤.
                _, predicted = torch.max(outputs, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()
        
            # í•œ ì—í­ì´ ëë‚œ í›„, ì „ì²´ í•™ìŠµ ë°ì´í„°ì— ëŒ€í•œ í‰ê·  ì†ì‹¤ê³¼ ì •í™•ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
            train_accuracy = correct / total
            train_loss = running_loss / len(trainloader)
            
            # TensorBoardì— í•™ìŠµ ì†ì‹¤ê³¼ ì •í™•ë„ë¥¼ ê¸°ë¡í•©ë‹ˆë‹¤.
            writer.add_scalar("Loss/train", train_loss, epoch)
            writer.add_scalar("Accuracy/train", train_accuracy, epoch)
        ```
        
    
- ì ìš© ì˜ˆì‹œ (PyTorch)
    
    ```python
    import torch  # PyTorch ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°
    import torch.nn as nn  # ì‹ ê²½ë§ ëª¨ë“ˆ ë¶ˆëŸ¬ì˜¤ê¸°
    import torch.optim as optim  # ìµœì í™” ì•Œê³ ë¦¬ì¦˜ ë¶ˆëŸ¬ì˜¤ê¸°
    import torchvision  # ì´ë¯¸ì§€ ì²˜ë¦¬ ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°
    import torchvision.transforms as transforms  # ë°ì´í„° ë³€í™˜ì„ ìœ„í•œ ëª¨ë“ˆ ë¶ˆëŸ¬ì˜¤ê¸°
    import matplotlib.pyplot as plt  # ê·¸ë˜í”„ë¥¼ ê·¸ë¦¬ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
    import numpy as np  # ìˆ˜í•™ ì—°ì‚°ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
    from torch.utils.data import DataLoader  # ë°ì´í„° ë¡œë” ëª¨ë“ˆ ë¶ˆëŸ¬ì˜¤ê¸°
    import time  # ì‹œê°„ ì¸¡ì •ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
    import IPython.display as display  # IPythonì—ì„œ ë””ìŠ¤í”Œë ˆì´ ê¸°ëŠ¥ í™œìš©
    from IPython.display import clear_output  # í™”ë©´ì„ ì§€ìš°ê¸° ìœ„í•œ ëª¨ë“ˆ
    
    # ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ ì„¤ì •
    transform_train = transforms.Compose([
        transforms.RandomHorizontalFlip(),  # ëœë¤ìœ¼ë¡œ ì¢Œìš° ë°˜ì „ ì ìš©
        transforms.RandomRotation(10),  # ëœë¤ìœ¼ë¡œ Â±10ë„ íšŒì „ ì ìš©
        transforms.RandomAffine(degrees=0, shear=10, scale=(0.8, 1.2)),  # ëœë¤ ë³€í˜• (ì´ë™, í™•ëŒ€/ì¶•ì†Œ, ê¸°ìš¸ê¸°)
        transforms.ToTensor(),  # ì´ë¯¸ì§€ë¥¼ í…ì„œ í˜•íƒœë¡œ ë³€í™˜
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # ì´ë¯¸ì§€ ì •ê·œí™” (í‰ê·  0, í‘œì¤€í¸ì°¨ 1)
    ])
    
    transform_test = transforms.Compose([
        transforms.ToTensor(),  # í…ŒìŠ¤íŠ¸ ë°ì´í„°ë„ í…ì„œ ë³€í™˜
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # ë™ì¼í•œ ì •ê·œí™” ì ìš©
    ])
    
    # CIFAR-10 ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ë° ë¡œë“œ
    trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)
    testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)
    
    # ë°ì´í„° ë¡œë” ìƒì„± (ë°°ì¹˜ í¬ê¸° 32)
    trainloader = DataLoader(trainset, batch_size=32, shuffle=True)  # í›ˆë ¨ ë°ì´í„° ë¡œë”
    testloader = DataLoader(testset, batch_size=32, shuffle=False)  # í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë”
    
    # CNN ëª¨ë¸ ì •ì˜
    class CNNModel(nn.Module):
        def __init__(self):
            super(CNNModel, self).__init__()
            self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)  # ì²« ë²ˆì§¸ í•©ì„±ê³±ì¸µ (ì…ë ¥: RGB 3ì±„ë„, ì¶œë ¥: 32ì±„ë„)
            self.pool = nn.MaxPool2d(kernel_size=2, stride=2)  # 2x2 ë§¥ìŠ¤ í’€ë§ ì ìš©
            self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)  # ë‘ ë²ˆì§¸ í•©ì„±ê³±ì¸µ (ì…ë ¥: 32ì±„ë„, ì¶œë ¥: 64ì±„ë„)
            self.fc1 = nn.Linear(64 * 8 * 8, 64)  # ì²« ë²ˆì§¸ ì™„ì „ ì—°ê²°ì¸µ (ì…ë ¥: 64x8x8, ì¶œë ¥: 64)
            self.fc2 = nn.Linear(64, 10)  # ë‘ ë²ˆì§¸ ì™„ì „ ì—°ê²°ì¸µ (ì¶œë ¥: 10 í´ë˜ìŠ¤)
    
        def forward(self, x):
            x = torch.relu(self.conv1(x))  # ì²« ë²ˆì§¸ í•©ì„±ê³±ì¸µ + ReLU í™œì„±í™” í•¨ìˆ˜ ì ìš©
            x = self.pool(x)  # ë§¥ìŠ¤ í’€ë§ ì ìš©
            x = torch.relu(self.conv2(x))  # ë‘ ë²ˆì§¸ í•©ì„±ê³±ì¸µ + ReLU í™œì„±í™” í•¨ìˆ˜ ì ìš©
            x = self.pool(x)  # ë§¥ìŠ¤ í’€ë§ ì ìš©
            x = x.view(-1, 64 * 8 * 8)  # 1ì°¨ì› ë²¡í„°ë¡œ ë³€í™˜
            x = torch.relu(self.fc1(x))  # ì²« ë²ˆì§¸ ì™„ì „ ì—°ê²°ì¸µ + ReLU í™œì„±í™” í•¨ìˆ˜ ì ìš©
            x = self.fc2(x)  # ë‘ ë²ˆì§¸ ì™„ì „ ì—°ê²°ì¸µ (ì¶œë ¥ì¸µ)
            return x
    
    # ì‹¤ì‹œê°„ ê·¸ë˜í”„ë¥¼ ê·¸ë¦¬ëŠ” í•¨ìˆ˜
    def plot_live(train_loss, val_loss, train_acc, val_acc):
        clear_output(wait=True)  # ì¶œë ¥ ì°½ì„ ì§€ìš°ê¸° (ìƒˆë¡œìš´ ê·¸ë˜í”„ë¥¼ ìœ„í•´)
        plt.figure(figsize=(12, 5))  # ê·¸ë˜í”„ í¬ê¸° ì„¤ì •
    
        plt.subplot(1, 2, 1)  # 1í–‰ 2ì—´ì˜ ì²« ë²ˆì§¸ ê·¸ë˜í”„ (ì†ì‹¤ê°’)
        plt.plot(train_loss, label="Train Loss", marker="o")
        plt.plot(val_loss, label="Validation Loss", marker="o")
        plt.xlabel("Epoch")
        plt.ylabel("Loss")
        plt.title("Loss Over Epochs")
        plt.legend()
    
        plt.subplot(1, 2, 2)  # 1í–‰ 2ì—´ì˜ ë‘ ë²ˆì§¸ ê·¸ë˜í”„ (ì •í™•ë„)
        plt.plot(train_acc, label="Train Accuracy", marker="o")
        plt.plot(val_acc, label="Validation Accuracy", marker="o")
        plt.xlabel("Epoch")
        plt.ylabel("Accuracy")
        plt.title("Accuracy Over Epochs")
        plt.legend()
    
        plt.show()  # ê·¸ë˜í”„ ì¶œë ¥
    
    # ëª¨ë¸ í•™ìŠµ í•¨ìˆ˜ ì •ì˜
    def train_model(model, trainloader, testloader, epochs=20):
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")  # GPU ì‚¬ìš© ì—¬ë¶€ í™•ì¸
        model.to(device)  # ëª¨ë¸ì„ GPUë¡œ ì´ë™
    
        criterion = nn.CrossEntropyLoss()  # ì†ì‹¤ í•¨ìˆ˜ (êµì°¨ ì—”íŠ¸ë¡œí”¼)
        optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adam ì˜µí‹°ë§ˆì´ì € ì„¤ì •
    
        train_loss, val_loss = [], []  # í›ˆë ¨ ë° ê²€ì¦ ì†ì‹¤ ì €ì¥ ë¦¬ìŠ¤íŠ¸
        train_acc, val_acc = [], []  # í›ˆë ¨ ë° ê²€ì¦ ì •í™•ë„ ì €ì¥ ë¦¬ìŠ¤íŠ¸
    
        for epoch in range(epochs):  # ì§€ì •í•œ ì—í¬í¬ ìˆ˜ë§Œí¼ ë°˜ë³µ
            model.train()  # ëª¨ë¸ì„ í›ˆë ¨ ëª¨ë“œë¡œ ì„¤ì •
            running_loss, correct, total = 0.0, 0, 0  # ì´ˆê¸° ì†ì‹¤ ë° ì •í™•ë„ ë³€ìˆ˜ ì„¤ì •
            for inputs, labels in trainloader:
                inputs, labels = inputs.to(device), labels.to(device)  # ë°ì´í„°ë¥¼ GPUë¡œ ì´ë™
                optimizer.zero_grad()  # ê¸°ìš¸ê¸° ì´ˆê¸°í™”
                outputs = model(inputs)  # ëª¨ë¸ ì˜ˆì¸¡ ìˆ˜í–‰
                loss = criterion(outputs, labels)  # ì†ì‹¤ ê³„ì‚°
                loss.backward()  # ì—­ì „íŒŒ ìˆ˜í–‰
                optimizer.step()  # ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸
                running_loss += loss.item()  # ì†ì‹¤ ëˆ„ì 
                _, predicted = torch.max(outputs, 1)  # ì˜ˆì¸¡ê°’ ê³„ì‚°
                total += labels.size(0)
                correct += (predicted == labels).sum().item()
    
            train_loss.append(running_loss / len(trainloader))  # í‰ê·  í›ˆë ¨ ì†ì‹¤ ì €ì¥
            train_acc.append(correct / total)  # í›ˆë ¨ ì •í™•ë„ ì €ì¥
    
            model.eval()  # ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •
            val_running_loss, correct, total = 0.0, 0, 0  # ì´ˆê¸° ì†ì‹¤ ë° ì •í™•ë„ ë³€ìˆ˜ ì„¤ì •
            with torch.no_grad():
                for inputs, labels in testloader:
                    inputs, labels = inputs.to(device), labels.to(device)
                    outputs = model(inputs)
                    loss = criterion(outputs, labels)
                    val_running_loss += loss.item()
                    _, predicted = torch.max(outputs, 1)
                    total += labels.size(0)
                    correct += (predicted == labels).sum().item()
    
            val_loss.append(val_running_loss / len(testloader))  # í‰ê·  ê²€ì¦ ì†ì‹¤ ì €ì¥
            val_acc.append(correct / total)  # ê²€ì¦ ì •í™•ë„ ì €ì¥
    
            plot_live(train_loss, val_loss, train_acc, val_acc)  # ì‹¤ì‹œê°„ ê·¸ë˜í”„ ì—…ë°ì´íŠ¸
    
        return train_loss, val_loss, train_acc, val_acc  # ê²°ê³¼ ë°˜í™˜
    ```
<br><br>
    

ëŸ°íŒŸ(RunPot) â†’ ëŒ€ê·œëª¨ ëª¨ë¸ í•™ìŠµ, gpu ì„ íƒ ê°€ëŠ¥

---

ì •ê·œí™” ê¸°ë²•

| ì •ê·œí™” ê¸°ë²• | ì„¤ëª… | ì‘ë™ ë°©ì‹ | íŠ¹ì§• |
| --- | --- | --- | --- |
| **L1 ì •ê·œí™” (Lasso ì •ê·œí™”)** | ê°€ì¤‘ì¹˜ì˜ ì ˆëŒ€ê°’ í•©ì— ë¹„ë¡€í•˜ëŠ” íŒ¨ë„í‹°ë¥¼ ì¶”ê°€ | ê°€ì¤‘ì¹˜ë¥¼ 0ìœ¼ë¡œ ë§Œë“¤ì–´ ëª¨ë¸ì„ í¬ì†Œí•˜ê²Œ í•¨ | ì¤‘ìš”í•˜ì§€ ì•Šì€ íŠ¹ì§•ì„ ì œê±°, ëª¨ë¸ì˜ í•´ì„ ê°€ëŠ¥ì„± ë†’ìŒ |
| **L2 ì •ê·œí™” (Ridge ì •ê·œí™”)** | ê°€ì¤‘ì¹˜ì˜ ì œê³±í•©ì— ë¹„ë¡€í•˜ëŠ” íŒ¨ë„í‹°ë¥¼ ì¶”ê°€ | ëª¨ë“  ê°€ì¤‘ì¹˜ë¥¼ ì‘ê²Œ ë§Œë“¤ì–´ ëª¨ë¸ì˜ ë³µì¡ë„ë¥¼ ì¤„ì„ | ëª¨ë“  íŠ¹ì§•ì´ ì¼ë¶€ ì˜í–¥ì„ ë¯¸ì¹¨, ë¶€ë“œëŸ¬ìš´ ëª¨ë¸ ìƒì„±, ì˜¤ë²„í”¼íŒ… ë°©ì§€ |
| **ì—˜ë¼ìŠ¤í‹±ë„· ì •ê·œí™” (Elastic Net)** | L1ê³¼ L2 ì •ê·œí™”ë¥¼ ë™ì‹œì— ì‚¬ìš© | L1ê³¼ L2 ì •ê·œí™”ì˜ ì¥ì ì„ ê²°í•© | ê³¼ì í•©ì„ íš¨ê³¼ì ìœ¼ë¡œ ë°©ì§€ |
| **Dropout** | ë”¥ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµ ì¤‘ ë¬´ì‘ìœ„ë¡œ ë‰´ëŸ°ì„ ë¹„í™œì„±í™”í•˜ì—¬ ê³¼ì í•© ë°©ì§€ | ê° í›ˆë ¨ ë‹¨ê³„ì—ì„œ íŠ¹ì • í™•ë¥ (p)ë¡œ ë‰´ëŸ°ì„ ë¹„í™œì„±í™” | íŠ¹ì • ë‰´ëŸ°ì´ë‚˜ ê²½ë¡œì— ì˜ì¡´í•˜ì§€ ì•Šê²Œ í•˜ì—¬ ë„¤íŠ¸ì›Œí¬ê°€ ë”ìš± ê²¬ê³ í•´ì§ |


---
  
### ğŸ“ ì°¸ê³  ìë£Œ ë° ë§í¬
- Alex ê°•ì˜
