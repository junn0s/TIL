## 📅 날짜: 2025-03-04

### 💬 스크럼
- 학습 목표 1 : ResNet, VGG
- 학습 목표 2 : Transfer Learning(fine tuning 등)
  
### 📒 공부한 내용
---
### Model Architecture <br><br>

CNN : 2D 정보의 특징 추출을 위해 사용 (공간 정보 소실을 막음)

모델 : 학습을 통해 찾아낸 최적 weight들의 집합 (파라미터들의 집합)

딥러닝 목적 : 복잡한 데이터에서 높은 수준의 특징을 자동으로 학습해 weight를 조정하는 것<br><br>

저수준 특징 : 이미지에서 엣지, 텍스처 등 기본 시각 요소

고수준 특징 : 사람이 하려는 것. 물체,얼굴,동작 등의 의미가 있는 요소<br><br>

학습 과정 : test data(최종 평가), validation data(중간 평가)


1. Epoch를 한 번 돌 때마다 모델이 하나씩 생성
2. Epoch을 모두 다 돈 뒤, Test Data를 사용해서 테스트를 진행
    1. 이 과정은 Epoch를 통해 만들어진 모델을 모두 테스트해야하기 때문에 Epoch 수만큼 반복<br><br>
---
### Pre-trained Model

사전 학습 모델 : 이미 훈련이 끝난 모델 혹은 파라미터

- 처음부터 구축하지 않고 시간 절약 가능<br><br>

모델 구조

Input (low) → hidden … → Output (top)

- lower layer (low쪽) : 기본 특징 추출 (저수준)
- upper layer (top쪽) : 고수준 특징 추출
- top : 상위 분류 레이어
- 기존 분류 레이어를 제외하고 앞 부분만 가져다가 씀 (내 경우에 맞도록)<br><br>



---

ResNet (Residual Network)

→ 입력과 출력의 차이를 학습하는 구조를 통해 성능을 향상시키는 딥러닝 모델의 한 종류<br><br>

역전파 시 레이어가 많을수록 정보 왜곡이 깊어짐 (기울기 손실)

→ Residual connection을 통해 깊은 네트워크에서도 기울기 소실을 줄일 수 있음<br><br>

Residual connection

- 이전 층의 정보를 연결하는 방식
    
    뒤로 갈수록 앞 기억을 더해서 진행
    
    [Google Colab](https://colab.research.google.com/drive/1CJFlyGTALSJpdBNSio0v3fyVq28Eyqp0?usp=sharing)
    

---

VGG (Visual Geometry Group)

- 16개의 layer로 구성된 CNN 구조
- 단순화, 강력한 성능
- 모든 합성곱 계층에서 3x3 필터 사용
- Max Pooling 사용하여 점진적으로 해상도를 줄여 특징 추출

- ImageNet 데이터셋으로 학습된 1억개의 파라미터를 가지는 모델임


    [Google Colab](https://colab.research.google.com/drive/1qzLYNK0Non9W4S5h4ZzNoZzj93wSncct?usp=sharing)
    
---
### Transfer Learning (Parameter Tuning)

전이 학습 : 사전 훈련된 모델을 그대로 사용 or 추가로 튜닝하여 사용

- Fine-tuning (미세 조정)
    - 전체 혹은 일부 가중치와 패턴 활용, 새로운 데이터에 맞게 재훈련
    - 전체적으로 가중치가 다 조정됨
- Feature Extraction (특징추출)
    - 중간 계층 가중치를 그대로 고정하여 특징 추출기로 활용, 마지막 분류 레이어만 새로 학습
    - 파인튜닝보다 적게 학습시킴
- Zero-Shot Learning (제로샷 학습)
    - 한 번도 보지 못한 클래스에 대해서도 모델이 예측할수 있도록 하는 것
    - 추가 학습 없이 대응하는 능력<br><br>

문제 해결 방법

- 모델 그대로 가져와 쓰기 : 문제 상황이 모델과 동일한 경우
- 새로 학습 시키기
- 파인튜닝 (추가 튜닝)
- 앙상블
- 새로 모델 만들기

---

Fine Tuning (미세 조정 - 재훈련)

- 사전 훈련된 모델을 새로운 데이터셋에 맞춰 미세 조정하여 성능 최적화하는 과정
- 새로운 데이터에 대해 모델 성능 최적화와 데이터 부족 문제 극복을 위함<br><br>

· Fine Tuning: 기존 모델의 가중치를 기반으로 새로운 데이터에 맞게 일부 또는 전체를 재학습하는 방식
· · **Fine-Tuned Pre-trained Convolution Layer (Feature Learning):** 사전 학습된 합성곱 계층을 유지하면서도 새로운 데이터에 맞게 가중치를 업데이트함
· · **Trained Fully Connected Layer (Classification):** 기존 분류기를 새로운 분류기로 교체하고, 새 데이터에 맞춰 완전히 학습함<br><br>

Fine-Tuned Pre-trained Convolution Layer : 리모델링

Trained Fully Connected Layer : 재건축<br><br>

종류

1. Full Fine Tuning : 가장 높은 성능, 많은 데이터와 학습 시간이 필요
        
2. Partial Fine Tuning : 일부 파라미터 조정, 학습 시간 단축

3. 단계적 파인튜닝 : 상위 레이어만 재학습, 다음 단계에서 하위 레이어까지 포함하여 재학습
        
4. 하이브리드 : 여러 방법 결합

    [Google Colab](https://colab.research.google.com/drive/1hLoDQCY56fxLt7zLD5U9vnlAFGpQYlFq?usp=sharing)
    

---

Feature Extraction (특징 추출)

- 사전 훈련된 모델의 중간 계층 가중치를 고정하여, 해당 계층을 특징 추출기로 사용하는 방식<br><br>

**· Feature Extraction:** 사전 학습된 모델의 합성곱 계층을 고정하고, 새로운 분류기만 학습하는 방식
· · **Frozen Pre-trained Convolution Layer (Feature Learning):** 사전 학습된 합성곱 계층을 고정하여 기존 모델의 특징을 그대로 활용함
· · **New Fully Connected Layer (Classification):** 새로운 데이터에 맞춰 완전히 새로운 분류기를 학습함<br><br>

frozen 부분 (feature learning) 을 그대로 따서 쓰고, 뒤쪽 분류기는 새로 학습하는 것


    [Google Colab](https://colab.research.google.com/drive/1hpZh6egNANiXYhShzaD7tc_Noxwi3dY2?usp=sharing)
    

---

Zero-Shot Learning (제로샷 학습)

- 훈련 데이터에 없는 새로운 클래스나 작업을 사전 지식이나 관련 정보를 활용해 ‘학습 없이’ 수행하는 기법
- 모델 스스로 알고 있는 개념과 연관지어 추론할 수 있도록 설계
    
<br><br>
    

사전 지식 : 모델이 미리 학습해둔 개념적 표현 혹은 다른 데이터 소스(텍스트 설명 등)

---

  
### 📁 참고 자료 및 링크
- Alex 강의
