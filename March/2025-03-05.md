## 📅 날짜: 2025-03-05

### 💬 스크럼
- 학습 목표 1 : Model Comparision
- 학습 목표 2 : Hyperparameter Tuning
  
### 📒 공부한 내용
---
### Model Comparision

모델 성능평가 및 비교

    [Google Colab](https://colab.research.google.com/drive/18NmH5drqiyLM2hjPBxWy5BEhQV_VdnIp?usp=sharing)
    

---

Overfitting(과적합)

- 학습 데이터를 과하게 학습해 실제 데이터에 대해서 오차가 증가하게 되는 것

<br>

· **좌측 그래프 (정확도)**: 학습 정확도는 지속적으로 증가하지만, 검증 정확도는 일정 수준 이후 감소하는 경향
· **우측 그래프 (오차)**: 학습 오차는 지속적으로 감소하지만, 검증 오차는 일정 시점 이후 다시 증가하는 모습
<br><br>

원인

- 파라미터 수가 너무 많음 : 복잡할수록 학습 데이터에 과적합되기 쉬움
- 데이터 양의 부족 : 데이터가 너무 적으면 모델이 데이터를 외우게 됨
- 노이즈 포함 학습 : 모델이 노이즈까지 학습하게 됨<br><br>

방지 방법

- 교차 검증 : 데이터를 여러 세트로 나누어 모델 평가
- 정규화 : 정규화 기법 사용 (데이터 정규화와는 다름)
- 데이터 양 증가
- 드롭아웃 : 일부 뉴런을 무작위로 학습하지 않도록 학습 대상에서 뺌 (지나친 학습 방지)
- 조기 종료 : 위 그림처럼 10번 학습 이후에 검증 데이터 오차 증가하므로 10번까지만 학습<br>


    [Google Colab](https://colab.research.google.com/drive/1pCuFh4ObuzyDHKfGyEz3ybT20fKLcb0-?usp=sharing)
    

---

Underfitting (과소적합)

- 학습을 충분히 하지 못해 성능이 낮은 경우
<br><br>

· **왼쪽 그래프 (Well-Fitted Model)
· · Accuracy (파란색)**: 학습이 진행됨에 따라 점진적으로 증가하여 최종적으로 95%에 도달
· · **Loss (빨간색)**: 꾸준히 감소하며 모델이 적절히 학습됨
· **오른쪽 그래프 (Underfitted Model)
· · Accuracy (파란색)**: 초기부터 성능이 낮고, 학습이 진행되어도 개선이 미미함
· · **Loss (빨간색)**: 높은 손실을 유지하며, 학습이 충분히 이루어지지 않은 상태<br><br>

방지 방법

- 모델 구조 개선 : 더 많은 레이어 추가, 필터 추가 등 복잡한 구조 추가
- 데이터 활용 최적화 : 더 많은 데이터 확보, 전처리 개선
- 학습 설정 조정 : 학습률, 최적화 알고리즘(optimizer), epoch 조정

---

Early Stopping (조기 중단)

- 훈련 시 과적합을 방지하기 위해 사용되는 정규화(regularization, 기술)의 한 형태
- 정규화 : 특화를 줄여서 일반화를 하려는 시도

<br><br>

· **왼쪽 그래프 (No Early Stopping)**:학습이 10 에포크까지 진행된 모델의 결과. 검증 손실(Val Loss)이 초반에는 감소하지만, **6 에포크 이후 다시 증가**하는 현상이 보임. 과적합(Overfitting)이 발생했음을 의미
· **오른쪽 그래프 (Early Stopping at Epoch 4)**: 4번째 에포크에서 조기 중단이 발생하여 학습 중단. 그 결과, **검증 손실이 증가하기 전에 학습이 멈춰 과적합 방지**

---

### Hyperparameter Tuning

fine tuning : 파라미터(가중치) 튜닝

hyperparameter tuning : 하이퍼파라미터 튜닝<br><br>

하이퍼파라미터 종류

- 학습률
- 배치 크기 (한번에 학습할 데이터 개수)
- 에포크
- 활성화 함수 (ReLU)
- 옵티마이저 (Adam)
- 모멘텀 (옵티마이저에 관성 추가)
- 드롭아웃 비율
- 초기화 방법 (최초 가중치 초기화 방법) → He, Glorot, Random

---

### 한 줄 정리

| 개념 | 정리 |
| --- | --- |
| 사전 학습 모델 | 많은 데이터로 미리 학습 완료된 모델, 새로운 작업 시 안정적 성능을 빠르게 적용 가능함 |
| 전이 학습 | 사전 학습 모델을 새로운 문제에 적용하는 것, 학습시간 단축과 성능 향상을 위해 사용함 |
| 미세 조정(Fine Tuning) | 사전 학습 모델을 새로운 데이터셋에 맞춰 세밀하게 조정하는 것, 성능 최적화와 데이터 부족 문제 극복을 위해 사용함 |
| 특징 추출(Feature Extraction) | 사전 학습 모델의 중간 계층을 고정해 일반적인 특징을 추출하고 이를 모델 최종 예측에 활용하는 방식, 성능 개선을 위해 사용함 |
| 과(대)적합(overfitting) | 모델이 학습 데이터에 지나치게 맞춰져 일반화 능력이 떨어지는 현상 |
| 과소적합(underfitting) | 모델이 충분한 학습을 하지 않아 예측을 제대로 못 하는 현상 |

---
  
### 📁 참고 자료 및 링크
- Alex 강의
