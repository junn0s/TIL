## 📅 날짜: 2025-02-21

### 💬 스크럼
- 학습 목표 1 : 딥다이브 주제 공부 및 설명
  
### 📒 공부한 내용
---
### 딥다이브

**주제 : PyTorch에서의 텐서 연산과 벡터 연산의 차이점을 설명하시오**<br><br>

벡터와 텐서

벡터 : 일반적으로 1차원 구조를 의미함. 1차원 텐서 = 벡터.

- `torch.tensor([1, 2, 3])`

텐서 : n차원 배열을 일반화한 개념. 스칼라, 벡터, 행렬, 그 이상 다차원 배열 모두를 포함함.

- `torch.tensor([[1, 2], [3, 4]])`<br><br>

연산의 차이

벡터 연산 : 1차원 연산을 기본으로 함. 원소별 덧셈, 내적 등 수행

- 연산 : 선형대수 관점에서 기본 연산(스칼라 곱, 덧셈, 뺄셈, 내적, 놈)
- 성능 : 연산 비용이 작음

텐서 연산 : 2차원 이상의 다차원에서 연산 수행. 자동 브로드캐스팅 규칙이 적용됨(차원 불일치 해소)

- 행렬 * 벡터, 행렬 * 행렬, 고차원 텐서 간 연산 등이 자동 브로드캐스팅
- 연산 : 합성곱 연산, 배치 연산, 고차원 행렬 분해, 행렬 곱 연산
- 성능 : 브로드캐스팅과 병렬 연산을 어떻게 하냐에 따라 달라짐.<br><br>

결론

파이토치에서는 모든 데이터를 텐서로 취급함. 벡터 연산도 텐서 연산의 한 종류임

즉 벡터 연산은 텐서 연산의 부분집합이며, 모두 텐서 객체를 기반으로 수행됨

- 차원에 따라 자동으로 처리됨.
- 즉 1차원 텐서(벡터) 에 대해 수행할 때는 벡터 연산, 2차원 이상에는 행렬 또는 고차원 연산으로 자동 해석됨
<br><br>
자동 해석? → 브로드캐스팅

텐서의 차원 정보(`shape`) 기반 연산

1. 모든 텐서는 `shape`(크기)와 `rank`(차원 수), `stride, dtype` 등의 정보를 포함함
2. 파이토치의 연산 (`torch.add, torch.sum` 등..) 은 텐서의 크기와 차원을 보고 연산 방식을 결정함
<br><br>    
    

코드

```python
import torch

# ------------------------
# 1. 벡터(1D 텐서) 연산 예시
# ------------------------
v1 = torch.tensor([1.0, 2.0, 3.0])
v2 = torch.tensor([4.0, 5.0, 6.0])

# (1) 원소별 연산
elementwise_sum = v1 + v2  # tensor([5., 7., 9.])
elementwise_mul = v1 * v2  # tensor([ 4., 10., 18.])

# (2) 내적(dot product)
dot_product = torch.dot(v1, v2)  # 1*4 + 2*5 + 3*6 = 32

# (3) 노름(norm)
v1_norm = torch.norm(v1)  # sqrt(1^2 + 2^2 + 3^2) = sqrt(14) ≈ 3.74

print("=== Vector Operations ===")
print("Elementwise Sum:", elementwise_sum)
print("Elementwise Mul:", elementwise_mul)
print("Dot Product:", dot_product)
print("v1 Norm:", v1_norm)

# ------------------------
# 2. 텐서(ND 텐서) 연산 예시
# ------------------------
# (1) 2차원 텐서 (행렬) 생성
A = torch.tensor([[1.0, 2.0],
                  [3.0, 4.0]])
B = torch.tensor([[5.0, 6.0],
                  [7.0, 8.0]])

# (2) 행렬 곱
matmul_result = torch.matmul(A, B)
# 또는 A @ B로도 표현 가능

# (3) 브로드캐스팅 예시
# shape: (2,2)인 행렬 A, shape: (2,)인 벡터 v3
v3 = torch.tensor([10.0, 20.0])
broadcast_sum = A + v3  # 브로드캐스팅을 통해 (2,2) + (2,) 연산이 가능

# (4) 3차원 텐서 예시
C = torch.randn(2, 3, 4)  # shape (2,3,4)
D = torch.randn(3, 4)     # shape (3,4)
tensor_sum = C + D        # shape이 (2,3,4)와 (3,4)이므로, 첫 번째 차원(배치)에서 브로드캐스팅 가능 -> (2,3,4)

print("\n=== Tensor Operations ===")
print("Matrix Multiplication:\n", matmul_result)
print("Broadcasted Sum with vector:\n", broadcast_sum)
print("3D Tensor + 2D Tensor (Broadcasting):\n", tensor_sum)
```

공식 문서 - 브로드캐스팅

pytorch/aten/src/ATen/ExpandUtils.cpp<br><br>

```cpp
// 두 텐서의 크기를 비교하여 브로드캐스팅 후의 크기를 추론하는 함수 템플릿
// Container: 결과를 담을 컨테이너 타입 (예: std::vector<int64_t>)
// ArrayType: 입력 배열 타입 (예: IntArrayRef)
Container infer_size_impl(ArrayType a, ArrayType b) {
  // a와 b의 차원 수(크기)를 ptrdiff_t 타입으로 저장하여 부호 있는 비교를 수행
  auto dimsA = static_cast<ptrdiff_t>(a.size());
  auto dimsB = static_cast<ptrdiff_t>(b.size());
  
  // 두 텐서 중 더 많은 차원을 갖는 쪽을 전체 차원(ndim)으로 결정
  auto ndim = dimsA > dimsB ? dimsA : dimsB;
  // 결과 크기를 저장할 컨테이너를 ndim 길이로 초기화
  Container expandedSizes(ndim);
	
	// 뒤쪽(마지막) 차원부터 앞으로 거꾸로 순회하면서 각 차원의 브로드캐스팅 결과 크기를 결정
  for (ptrdiff_t i = ndim - 1; i >= 0; --i) {
	  // offset: 전체 ndim에서 현재 i번째 차원이 뒤쪽에서 몇 번째인지를 나타냄
	  // 예를 들어, ndim이 4이고 i가 3라면 offset은 0, i가 2라면 offset은 1
    ptrdiff_t offset = ndim - 1 - i;
    // a와 b에서 비교할 차원 인덱스 계산
    ptrdiff_t dimA = dimsA - 1 - offset;
    ptrdiff_t dimB = dimsB - 1 - offset;
    // 해당 차원이 존재하지 않으면 1로 간주
    auto sizeA = (dimA >= 0) ? a[dimA] : 1;
    auto sizeB = (dimB >= 0) ? b[dimB] : 1;
		
		
		// 각 인덱스 별로 값이 같거나 1이어야 함(즉 해당 차원이 없어야 함)
    TORCH_CHECK(
        sizeA == sizeB || sizeA == 1 || sizeB == 1,
        "The size of tensor a (", sizeA,
        ") must match the size of tensor b (", sizeB,
        ") at non-singleton dimension ", i);

      // 만약 sizeA가 1이면, 브로드캐스팅 되어 sizeB가 적용됨
	    // 그렇지 않으면 sizeA를 그대로 사용합니다
      expandedSizes[i] = sizeA == 1 ? sizeB : sizeA;
  }
	// 최종적으로 브로드캐스팅 후의 크기를 담은 컨테이너를 반환
  return expandedSizes;
}
}
```

코드 설명

`infer_size_impl` 함수

두 개의 텐서 크기를 뒤쪽부터 비교하면서, 각 차원에 대해 브로드캐스팅 가능한지 검사, 최종 크기 출력

한쪽 크기가 1이라면 다른 텐서의 해당 차원 크기로 설정, 두 크기가 같다면 그대로 사용

예 ) 텐서 A가 shape (5, 3) 이고 텐서 B는 shape (3)이라면 텐서 B는 자동으로 shape (1, 3) 으로 변환, 최종 변환 크기는 (5, 3)

- 오른쪽부터 비교하는 이유 : 추가 차원을 허용하려면 차원이 작은 오른쪽부터 비교해야 함. 동일한 연산을 할 수 있도록, 즉 반복해서 적용할 수 있도록 하기 위해 오른쪽부터 비교
<br><br><br><br>
```cpp
// 원래 텐서의 크기와 메모리 정보를 바탕으로 브로드캐스팅 후의 새로운 "기하학"을 추론하는 함수
// Container는 결과를 저장할 컨테이너 타입 (예: std::vector<int64_t>)
// InferExpandGeometryResult는 결과로 (새로운 크기와 스트라이드)를 담는 구조체
template<typename Container>
C10_ALWAYS_INLINE InferExpandGeometryResult<Container> inferExpandGeometryImpl(
    IntArrayRef tensor_sizes,    // 원래 텐서의 크기 배열
    IntArrayRef tensor_strides,  // 원래 텐서의 스트라이드 배열
    IntArrayRef sizes) {         // 브로드캐스팅 후 목표 크기 배열 (새로운 shape)
  
  // 전체 차원(ndim)은 목표 크기 배열의 길이로 결정
  int64_t ndim = static_cast<int64_t>(sizes.size());
  // 원래 텐서의 차원 수
  int64_t tensor_dim = static_cast<int64_t>(tensor_sizes.size());

  // 만약 원래 텐서가 스칼라(0차원)라면,
  // 목표 크기를 그대로 결과로 반환
  if (tensor_dim == 0) {
    return InferExpandGeometryResult<Container>(sizes, ndim);
  }

  // 결과를 담을 InferExpandGeometryResult 객체를 ndim 길이로 초기화
  InferExpandGeometryResult<Container> result(ndim);
  auto& expandedSizes = result.sizes;   // 결과 크기 배열에 대한 별칭
  auto& expandedStrides = result.strides; // 결과 스트라이드 배열에 대한 별칭

  // 텐서의 새로운 기하학(크기와 스트라이드)을 계산하기 위해, 뒤쪽(오른쪽)부터 순회
  // 왜냐하면 브로드캐스팅은 오른쪽(마지막) 차원부터 비교하기 때문
  for (int64_t i = ndim - 1; i >= 0; --i) {
    int64_t offset = ndim - 1 - i;
    int64_t dim = tensor_dim - 1 - offset;
    int64_t size = (dim >= 0) ? tensor_sizes[dim] : 1;
    // 만약 해당 차원이 원래 텐서에 있다면 해당 스트라이드를, 없으면
    // 다음 차원의 (즉, 오른쪽 차원) 확장된 크기와 스트라이드를 곱한 값으로 계산
    // 이는 새롭게 추가된 차원의 경우 연속된 메모리에서의 접근을 의미
    int64_t stride = (dim >= 0) ? tensor_strides[dim]
                                : expandedSizes[i + 1] * expandedStrides[i + 1];
    // 목표 크기(targetSize)는 브로드캐스팅 후 사용자가 원하는 크기
    int64_t targetSize = sizes[i];
    
    // 만약 targetSize가 -1이면, 이는 특별한 값으로서 기존 크기를 유지해야 함을 의미
    if (targetSize == -1) {
      // 이미 원래 텐서에 해당 차원이 존재해야 함
      TORCH_CHECK(
          dim >= 0,
          "The expanded size of the tensor (", targetSize,
          ") isn't allowed in a leading, non-existing dimension ", i);
      // targetSize를 기존의 크기로 설정
      targetSize = size;
    }
    // 만약 기존 크기(size)와 목표 크기(targetSize)가 다르다면,
    // 브로드캐스팅 규칙에 따라 기존 크기가 1이어야 함
    if (size != targetSize) {
      TORCH_CHECK(
          size == 1,  // 기존 크기가 1인 경우에만 다른 크기로 확장이 가능함
          "The expanded size of the tensor (", targetSize,
          ") must match the existing size (", size,
          ") at non-singleton dimension ", i,
          ".  Target sizes: ", sizes,
          ".  Tensor sizes: ", tensor_sizes);
      // 크기를 목표 크기로 변경하고, 해당 차원의 stride는 0으로 설정
      // stride가 0이면, 해당 차원은 브로드캐스팅 되어 같은 값을 반복 사용함을 의미
      size = targetSize;
      stride = 0;
    }
    // 현재 차원의 확장된 크기와 스트라이드를 결과에 저장
    expandedSizes[i] = size;
    expandedStrides[i] = stride;
  }
  // 최종적으로 확장된 크기와 스트라이드를 담은 결과를 반환
  return result;
}
```

코드 설명

`inferExpandGeometryImpl` 함수

브로드캐스트 할 때 원래 텐서의 크기와 메모리 레이아웃(스트라이드) 정보를 바탕으로 사용자가 원하는 새로운 크기(목표 shape) 에 맞게 텐서의 ‘기하학’, 즉 크기와 스트라이드를 재계산하는 함수

→ 브로드캐스팅된 최종 크기 출력 및 해당 shape에 맞게 텐서 메모리 레이아웃을 재구성하기 위한 stride 정보까지 함께 계산한 ‘기하학’ 정보 반환

→ 스트라이드 : 텐서에서 각 차원을 따라 한 요소에서 다음 요소로 이동할 때 메모리 상에서 몇 칸을 건너뛰어야 하는지를 나타내는 값

- 예) 행렬
마지막(가장 오른쪽) 차원의 스트라이드는 일반적으로 1. 이는 한 열의 다음 원소로 가기 위해 메모리 상에서 한 칸씩 이동한다는 의미
두 번째 차원의 스트라이드는 마지막 차원의 크기(즉, 열의 수)입니다. 왜냐하면, 다음 행의 같은 열에 접근하기 위해서는 그 행 전체의 데이터를 건너뛰어야 하기 때문

  
### 📁 참고 자료 및 링크
- github 및 파이토치 공식 문서 중 텐서와 브로드캐스팅
